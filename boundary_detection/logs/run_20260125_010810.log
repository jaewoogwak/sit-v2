[run.sh] Log file: /dev/ssd1/gjw/prvr/semantic-transformer-v2/boundary_detection/logs/run_20260125_010810.log
[run.sh] Merged train/val JSONL: ./output/activitynet_trainval_merged.jsonl
[run.sh] Inference JSONLs: /dev/hdd2/gjw/datasets/activitynet/activitynet_train.jsonl,/dev/hdd2/gjw/datasets/activitynet/activitynet_val.jsonl
[run.sh] Inference outputs: ./output/boundaries_act_train.json,./output/boundaries_act_val.json
[run.sh] Coarse mode: peaks (sim_threshold=0.65)
[run.sh] Fine params: seq_len=3 feature_dim=512 batch_size=128 lr=1e-4 epochs=20 layers=2 heads=8 ff_dim=1024 use_local_max=0 alpha=3 threshold_std=1.0 segment_pooling=self_attn
[run.sh] Level params: seq_len=3 batch_size=128 lr=1e-4 epochs=20 layers=2 heads=8 ff_dim=1024 use_local_max=0 alpha=2 threshold_std=0 threshold_mode=mad ckpt_dir=./checkpoints/level
[run.sh] Recursive params: levels=5 until_one=1 seq_len=3 seq_len_list= alpha=2 alpha_list= a=0 a_list= checkpoint= use_local_max=0
[run.sh] Mode: fine+recursive+coarse
epoch 1 loss 0.001656 time 35.17s
epoch 2 loss 0.000902 time 29.85s
epoch 3 loss 0.000779 time 29.76s
epoch 4 loss 0.000700 time 29.92s
epoch 5 loss 0.000643 time 29.74s
epoch 6 loss 0.000600 time 29.73s
epoch 7 loss 0.000566 time 29.76s
epoch 8 loss 0.000538 time 29.79s
epoch 9 loss 0.000517 time 30.00s
epoch 10 loss 0.000500 time 30.05s
epoch 11 loss 0.000485 time 29.74s
epoch 12 loss 0.000473 time 29.76s
epoch 13 loss 0.000462 time 29.69s
epoch 14 loss 0.000452 time 29.64s
epoch 15 loss 0.000443 time 29.61s
epoch 16 loss 0.000436 time 29.67s
epoch 17 loss 0.000429 time 29.69s
epoch 18 loss 0.000423 time 29.67s
epoch 19 loss 0.000417 time 29.75s
epoch 20 loss 0.000412 time 29.79s
[run.sh] Coarse trainval segment H5: ./output/segments_trainval.h5
[run.sh] Coarse trainval boundaries: ./output/boundaries_trainval_fine.json
/dev/ssd1/gjw/prvr/semantic-transformer-v2/boundary_detection/inference_boundary.py:375: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(args.checkpoint, map_location=device)
