#!/usr/bin/env python3
"""
ê¸°ì¡´ MSRVTT í”¼ì³ ë°ì´í„°ë¥¼ ActivityNet í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
- ê¸°ì¡´ HDF5 ë¹„ë””ì˜¤ í”¼ì³ì™€ í…ìŠ¤íŠ¸ í”¼ì³ë¥¼ ActivityNet í˜•ì‹ìœ¼ë¡œ ì¬êµ¬ì„±
- Caption íŒŒì¼ë“¤ì„ ActivityNetê³¼ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ìƒì„±
"""

import os
import json
import h5py
import numpy as np
from pathlib import Path
from tqdm import tqdm
from typing import Dict, List, Tuple
import shutil


def load_msrvtt_data(json_path: str) -> Tuple[Dict, List]:
    """MSRVTT JSON ë°ì´í„° ë¡œë“œ"""
    with open(json_path, 'r') as f:
        data = json.load(f)
    
    # ë¹„ë””ì˜¤ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    videos = {video['video_id']: video for video in data['videos']}
    sentences = data['sentences']
    
    return videos, sentences


def create_train_test_splits(videos: Dict, sentences: List) -> Tuple[List, List]:
    """Train/Test split ìƒì„± (MSRVTT í‘œì¤€ split: ì²˜ìŒ 9000ê°œ train, ë‚˜ë¨¸ì§€ test)"""
    train_data = []
    test_data = []
    
    # ë¹„ë””ì˜¤ë³„ë¡œ ìº¡ì…˜ë“¤ ê·¸ë£¹í™”
    video_captions = {}
    for sent in sentences:
        video_id = sent['video_id']
        if video_id not in video_captions:
            video_captions[video_id] = []
        video_captions[video_id].append(sent['caption'])
    
    # MSRVTT í‘œì¤€ split: video0-8999ëŠ” train, video9000-9999ëŠ” test/val
    for video_id in sorted(videos.keys()):  # video0, video1, ..., video9999 ìˆœì„œë¡œ
        if video_id in video_captions:
            captions = video_captions[video_id]
            
            # video IDì—ì„œ ìˆ«ì ì¶”ì¶œ
            video_num = int(video_id.replace('video', ''))
            
            if video_num < 6513:  # 0-6512: train set (ê¸°ì¡´ MSRVTT train split)
                for i, caption in enumerate(captions):
                    train_data.append({
                        'video_id': video_id,
                        'caption_id': f"{video_id}#enc#{i}",
                        'caption': caption
                    })
            else:  # 6513-9999: test set
                # Test ë°ì´í„°ëŠ” ëª¨ë“  ìº¡ì…˜ ì‚¬ìš© (ActivityNetê³¼ëŠ” ë‹¬ë¦¬)
                for i, caption in enumerate(captions):
                    test_data.append({
                        'video_id': video_id,
                        'caption_id': f"{video_id}#enc#{i}",
                        'caption': caption
                    })
    
    return train_data, test_data


def convert_video_features(input_hdf5: str, output_hdf5: str, video_ids: List[str]) -> None:
    """ë¹„ë””ì˜¤ í”¼ì³ë¥¼ ActivityNet í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    print(f"ğŸ“¥ ë¹„ë””ì˜¤ í”¼ì³ ë³€í™˜ ì¤‘: {input_hdf5} -> {output_hdf5}")
    
    # ê¸°ì¡´ MSRVTT HDF5 íŒŒì¼ êµ¬ì¡° í™•ì¸
    with h5py.File(input_hdf5, 'r') as f_in:
        print(f"ì…ë ¥ HDF5 í‚¤ë“¤: {list(f_in.keys())}")
        
        # êµ¬ì¡° í™•ì¸
        if 'features' in f_in and 'video_ids' in f_in:
            # ë°°ì—´ í˜•ì‹: {features: (N, frames, 512), video_ids: (N,)}
            features = f_in['features'][...]  # (N, frames, 512)
            video_id_array = f_in['video_ids'][...]  # (N,)
            
            print(f"Features shape: {features.shape}")
            print(f"Video IDs shape: {video_id_array.shape}")
            
            # ActivityNet í˜•ì‹ìœ¼ë¡œ ë³€í™˜: {video_id: (frames, 512)}
            with h5py.File(output_hdf5, 'w') as f_out:
                for i, video_id in enumerate(tqdm(video_id_array, desc="ë¹„ë””ì˜¤ í”¼ì³ ë³€í™˜")):
                    if isinstance(video_id, bytes):
                        video_id = video_id.decode('utf-8')
                    
                    # ê° ë¹„ë””ì˜¤ì˜ í”¼ì³ ì¶”ì¶œ (frames, 512)
                    video_feature = features[i]  # (frames, 512)
                    
                    # ActivityNet í˜•ì‹ìœ¼ë¡œ ì €ì¥
                    f_out[video_id] = video_feature.astype(np.float32)
        
        elif len(list(f_in.keys())) > 100:  # ì´ë¯¸ video_id í‚¤ í˜•ì‹ì¸ ê²½ìš°
            # ê·¸ëŒ€ë¡œ ë³µì‚¬
            print("ì´ë¯¸ ActivityNet í˜•ì‹ì…ë‹ˆë‹¤. ë³µì‚¬ ì¤‘...")
            shutil.copy2(input_hdf5, output_hdf5)
        
        else:
            print(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” HDF5 êµ¬ì¡°: {list(f_in.keys())}")


def create_text_features_hdf5(train_data: List, test_data: List, 
                             input_text_hdf5: str, output_hdf5: str) -> None:
    """í…ìŠ¤íŠ¸ í”¼ì³ë¥¼ ActivityNet í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    print(f"ğŸ’¬ í…ìŠ¤íŠ¸ í”¼ì³ ë³€í™˜ ì¤‘: {input_text_hdf5} -> {output_hdf5}")
    
    # ëª¨ë“  ìº¡ì…˜ IDì™€ í…ìŠ¤íŠ¸ ë§¤í•‘
    caption_id_to_text = {}
    for item in train_data + test_data:
        caption_id_to_text[item['caption_id']] = item['caption']
    
    # ê¸°ì¡´ í…ìŠ¤íŠ¸ í”¼ì³ ë¡œë“œ (ìºì‹œëœ í”¼ì³ ì‚¬ìš©)
    if os.path.exists(input_text_hdf5):
        print("ê¸°ì¡´ í…ìŠ¤íŠ¸ í”¼ì³ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        shutil.copy2(input_text_hdf5, output_hdf5)
    else:
        print("âš ï¸  í…ìŠ¤íŠ¸ í”¼ì³ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ í”¼ì³ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        with h5py.File(output_hdf5, 'w') as f:
            for caption_id in tqdm(caption_id_to_text.keys(), desc="ë¹ˆ í…ìŠ¤íŠ¸ í”¼ì³ ìƒì„±"):
                f[caption_id] = np.zeros(512, dtype=np.float32)


def create_caption_files(train_data: List, test_data: List, output_dir: str) -> None:
    """ActivityNet í˜•ì‹ì˜ caption íŒŒì¼ë“¤ ìƒì„±"""
    
    output_path = Path(output_dir)
    text_data_dir = output_path / 'TextData'
    text_data_dir.mkdir(parents=True, exist_ok=True)
    
    # Train caption íŒŒì¼
    train_file = text_data_dir / 'msrvtttrain.caption.txt'
    with open(train_file, 'w', encoding='utf-8') as f:
        for item in train_data:
            f.write(f"{item['caption_id']} {item['caption']}\n")
    
    # Test caption íŒŒì¼
    test_file = text_data_dir / 'msrvtttest.caption.txt'
    with open(test_file, 'w', encoding='utf-8') as f:
        for item in test_data:
            f.write(f"{item['caption_id']} {item['caption']}\n")
    
    # Val caption íŒŒì¼ (testì™€ ë™ì¼)
    val_file = text_data_dir / 'msrvttval.caption.txt'
    with open(val_file, 'w', encoding='utf-8') as f:
        for item in test_data:
            f.write(f"{item['caption_id']} {item['caption']}\n")
    
    print(f"âœ… Caption íŒŒì¼ë“¤ ìƒì„± ì™„ë£Œ:")
    print(f"  - Train: {len(train_data)}ê°œ ({train_file})")
    print(f"  - Test: {len(test_data)}ê°œ ({test_file})")
    print(f"  - Val: {len(test_data)}ê°œ ({val_file})")


def create_video2frames_file(output_dir: str, video_hdf5_path: str) -> None:
    """video2frames.txt íŒŒì¼ ìƒì„±"""
    
    video2frames = {}
    
    with h5py.File(video_hdf5_path, 'r') as f:
        for video_id in f.keys():
            # MSRVTTëŠ” ê° ë¹„ë””ì˜¤ê°€ í•˜ë‚˜ì˜ í‚¤ë¡œ ì €ì¥ë˜ë¯€ë¡œ ìê¸° ìì‹ ì„ í”„ë ˆì„ìœ¼ë¡œ ì„¤ì •
            video2frames[video_id] = [video_id]
    
    print(f"ì´ {len(video2frames)}ê°œ ë¹„ë””ì˜¤ ì²˜ë¦¬ë¨")
    
    # FeatureData/clip ë””ë ‰í„°ë¦¬ ìƒì„±
    output_path = Path(output_dir)
    feature_clip_dir = output_path / 'FeatureData' / 'clip'
    feature_clip_dir.mkdir(parents=True, exist_ok=True)
    
    # video2frames.txt íŒŒì¼ ì‘ì„±
    output_file = feature_clip_dir / 'video2frames.txt'
    with open(output_file, 'w') as f:
        f.write(str(video2frames))
    
    print(f"âœ… video2frames.txt ìƒì„± ì™„ë£Œ: {output_file}")
    print(f"ì˜ˆì‹œ: {list(video2frames.items())[:3]}")


def main():
    # ì„¤ì •
    msrvtt_json_path = '/disk/gjw/msr-vtt/MSRVTT_data.json'
    input_video_hdf5 = '/disk/gjw/msrvtt/FeatureData/new_clip_vit_32_msrvtt_vid_features.hdf5'
    input_text_hdf5 = '/disk/gjw/msrvtt/TextData/clip_ViT_B_32_msrvtt_query_feat.hdf5'
    output_dir = '/disk/gjw/msrvtt_activitynet_format'
    
    print(f"ğŸš€ MSRVTT -> ActivityNet í˜•ì‹ ë³€í™˜ ì‹œì‘")
    
    # ì¶œë ¥ ë””ë ‰í„°ë¦¬ ìƒì„±
    output_path = Path(output_dir)
    feature_data_dir = output_path / 'FeatureData'
    text_data_dir = output_path / 'TextData'
    feature_data_dir.mkdir(parents=True, exist_ok=True)
    text_data_dir.mkdir(parents=True, exist_ok=True)
    
    # MSRVTT ë°ì´í„° ë¡œë“œ
    print("ğŸ“‚ MSRVTT ë©”íƒ€ë°ì´í„° ë¡œë”©...")
    videos, sentences = load_msrvtt_data(msrvtt_json_path)
    print(f"ë¹„ë””ì˜¤: {len(videos)}ê°œ, ìº¡ì…˜: {len(sentences)}ê°œ")
    
    # Train/Test split ìƒì„±
    print("ğŸ”„ Train/Test split ìƒì„±...")
    train_data, test_data = create_train_test_splits(videos, sentences)
    print(f"Train: {len(train_data)}ê°œ, Test: {len(test_data)}ê°œ")
    
    # ë¹„ë””ì˜¤ í”¼ì³ ë³€í™˜
    print("ğŸ¥ ë¹„ë””ì˜¤ í”¼ì³ ë³€í™˜ ì¤‘...")
    video_hdf5_path = feature_data_dir / 'new_clip_vit_32_msrvtt_vid_features.hdf5'
    convert_video_features(input_video_hdf5, str(video_hdf5_path), list(videos.keys()))
    
    # í…ìŠ¤íŠ¸ í”¼ì³ ë³€í™˜
    print("ğŸ’¬ í…ìŠ¤íŠ¸ í”¼ì³ ë³€í™˜ ì¤‘...")
    text_hdf5_path = text_data_dir / 'clip_ViT_B_32_msrvtt_query_feat.hdf5'
    create_text_features_hdf5(train_data, test_data, input_text_hdf5, str(text_hdf5_path))
    
    # Caption íŒŒì¼ ìƒì„±
    print("ğŸ“ Caption íŒŒì¼ ìƒì„± ì¤‘...")
    create_caption_files(train_data, test_data, output_dir)
    
    # video2frames.txt íŒŒì¼ ìƒì„±
    print("ğŸ—‚ï¸  video2frames.txt ìƒì„± ì¤‘...")
    create_video2frames_file(output_dir, str(video_hdf5_path))
    
    print(f"\nâœ… ActivityNet í˜•ì‹ ë³€í™˜ ì™„ë£Œ!")
    print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í„°ë¦¬: {output_dir}")
    print(f"ğŸ“Š í†µê³„:")
    print(f"  - ì´ ë¹„ë””ì˜¤: {len(videos)}ê°œ")
    print(f"  - Train ìº¡ì…˜: {len(train_data)}ê°œ")
    print(f"  - Test ìº¡ì…˜: {len(test_data)}ê°œ")
    print(f"ğŸ¯ ActivityNetê³¼ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ë¨!")


if __name__ == '__main__':
    main()